{
 "cells": [
  {
   "metadata": {
    "id": "1cfec7ae913db671"
   },
   "cell_type": "markdown",
   "source": [
    "## Seq2Seq Model\n",
    "\n",
    "### Data loaders\n",
    "\n",
    "The final step of preparing the data is to create the data loaders.\n",
    "Our goal is to return a batch of data, each batch being a dictionary containing the numericalized sentences (which have also been padded) as PyTorch tensors."
   ],
   "id": "1cfec7ae913db671"
  },
  {
   "metadata": {
    "id": "d916dd2b9945a8a0",
    "ExecuteTime": {
     "end_time": "2024-08-04T14:08:21.140716Z",
     "start_time": "2024-08-04T14:08:20.032935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import sentencepiece as spm\n",
    "import itertools\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader"
   ],
   "id": "d916dd2b9945a8a0",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "id": "77f82a4c70b6f8ba",
    "ExecuteTime": {
     "end_time": "2024-08-04T14:08:22.336238Z",
     "start_time": "2024-08-04T14:08:22.332883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_collate_fn(pad_index):\n",
    "    def collate_fn(batch):\n",
    "        batch_src_ids = [example[\"src_ids\"] for example in batch]\n",
    "        batch_tgt_ids = [example[\"tgt_ids\"] for example in batch]\n",
    "        batch_src_ids = nn.utils.rnn.pad_sequence(batch_src_ids, padding_value=pad_index)\n",
    "        batch_tgt_ids = nn.utils.rnn.pad_sequence(batch_tgt_ids, padding_value=pad_index)\n",
    "        batch = {\n",
    "            \"src_ids\": batch_src_ids,\n",
    "            \"tgt_ids\": batch_tgt_ids,\n",
    "        }\n",
    "        return batch\n",
    "\n",
    "    return collate_fn"
   ],
   "id": "77f82a4c70b6f8ba",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "id": "1f5ee17c9da7b060"
   },
   "cell_type": "markdown",
   "source": [
    "Next, we write the functions which give us our data loaders creating using PyTorch's DataLoader class.\n",
    "get_data_loader is created using a Dataset, the batch size, the padding token index (which is used for creating the batches in the collate_fn, and a boolean deciding if the examples should be shuffled at the time the data loader is iterated over.\n",
    "The batch size defines the maximum amount of examples within a batch. If the length of the dataset is not evenly divisible by the batch size then the last batch will be smaller."
   ],
   "id": "1f5ee17c9da7b060"
  },
  {
   "metadata": {
    "id": "68f07d33bc08875f",
    "ExecuteTime": {
     "end_time": "2024-08-04T14:08:23.607371Z",
     "start_time": "2024-08-04T14:08:23.605694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return data_loader"
   ],
   "id": "68f07d33bc08875f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "id": "cdccc46c1e8cd4dc",
    "ExecuteTime": {
     "end_time": "2024-08-04T14:08:24.184837Z",
     "start_time": "2024-08-04T14:08:24.181926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = 'bpe_8000'"
   ],
   "id": "cdccc46c1e8cd4dc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "552f4b859db744f8",
    "outputId": "caa3b207-a1d5-488c-eddc-622c7003acc3",
    "ExecuteTime": {
     "end_time": "2024-08-04T14:08:34.825633Z",
     "start_time": "2024-08-04T14:08:33.424853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = torch.load(\"data/tokenized_data/bpe_8000_train.pt\")\n",
    "dev_data = torch.load(\"data/tokenized_data/bpe_8000_dev.pt\")\n",
    "test_data = torch.load(\"data/tokenized_data/bpe_8000_test.pt\")"
   ],
   "id": "552f4b859db744f8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "id": "80decdf60398939",
    "ExecuteTime": {
     "end_time": "2024-08-04T14:08:35.451965Z",
     "start_time": "2024-08-04T14:08:35.441408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_filename = 'tokenizer_models/' + model_name + '.model'\n",
    "sp = spm.SentencePieceProcessor(model_file=model_filename)"
   ],
   "id": "80decdf60398939",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "#\n",
    "\n",
    "\n",
    "# Generate all combinations of hyperparameters\n",
    "param_combinations = list(itertools.product(*param_grid.values()))\n"
   ],
   "metadata": {
    "id": "TnpxmDwckPDQ",
    "ExecuteTime": {
     "end_time": "2024-08-04T14:08:36.440489Z",
     "start_time": "2024-08-04T14:08:36.437687Z"
    }
   },
   "id": "TnpxmDwckPDQ",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "id": "b452bafe84aa74b0"
   },
   "cell_type": "markdown",
   "source": [
    "### Building  a model\n",
    "#### Encoder\n",
    "convert words into vectors\n",
    "\n",
    "* input_dim is the input (source) vocabulary size\n",
    "* embedding_dim is the dimensionality of the embedding layer.\n",
    "* hidden_dim is the dimensionality of the hidden and cell states.\n",
    "* n_layers is the number of layers in the RNN.\n",
    "* dropout is the amount of dropout to use to prevent overfitting."
   ],
   "id": "b452bafe84aa74b0"
  },
  {
   "metadata": {
    "id": "333d2c5448e31110",
    "ExecuteTime": {
     "end_time": "2024-08-04T14:08:38.019759Z",
     "start_time": "2024-08-04T14:08:38.017565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        return hidden, cell"
   ],
   "id": "333d2c5448e31110",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "id": "cbd807ef8a026cae",
    "ExecuteTime": {
     "end_time": "2024-08-04T14:08:38.427538Z",
     "start_time": "2024-08-04T14:08:38.424941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        return prediction, hidden, cell"
   ],
   "id": "cbd807ef8a026cae",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "id": "94f8f70283fdfb6b",
    "ExecuteTime": {
     "end_time": "2024-08-04T14:08:38.763491Z",
     "start_time": "2024-08-04T14:08:38.760404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        assert (\n",
    "            encoder.hidden_dim == decoder.hidden_dim\n",
    "        ), \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert (\n",
    "            encoder.n_layers == decoder.n_layers\n",
    "        ), \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "    def forward(self, src, tgt, teacher_forcing_ratio):\n",
    "        batch_size = tgt.shape[1]\n",
    "        tgt_length = tgt.shape[0]\n",
    "        tgt_vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(tgt_length, batch_size, tgt_vocab_size).to(self.device)\n",
    "        hidden, cell = self.encoder(src)\n",
    "        input = tgt[0, :]\n",
    "        # input = [batch size]\n",
    "        for t in range(1, tgt_length):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = tgt[t] if teacher_force else top1\n",
    "        return outputs"
   ],
   "id": "94f8f70283fdfb6b",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)"
   ],
   "metadata": {
    "id": "RXJQaJ85lu0W",
    "ExecuteTime": {
     "end_time": "2024-08-04T14:08:39.304137Z",
     "start_time": "2024-08-04T14:08:39.302242Z"
    }
   },
   "id": "RXJQaJ85lu0W",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ],
   "metadata": {
    "id": "hPp9cnFel023",
    "ExecuteTime": {
     "end_time": "2024-08-04T14:08:39.693945Z",
     "start_time": "2024-08-04T14:08:39.692247Z"
    }
   },
   "id": "hPp9cnFel023",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "id": "16716a9bb375c138",
    "ExecuteTime": {
     "end_time": "2024-08-04T14:08:40.157124Z",
     "start_time": "2024-08-04T14:08:40.155344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pad_index = 0\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_index)"
   ],
   "id": "16716a9bb375c138",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "id": "33656d484447460f",
    "ExecuteTime": {
     "end_time": "2024-08-04T14:08:41.249121Z",
     "start_time": "2024-08-04T14:08:41.245749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_fn(\n",
    "    model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device\n",
    "):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        src = batch[\"src_ids\"].to(device)\n",
    "        tgt = batch[\"tgt_ids\"].to(device)\n",
    "        # src = [src length, batch size]\n",
    "        # tgt = [tgt length, batch size]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt, teacher_forcing_ratio)\n",
    "        # output = [tgt length, batch size, tgt vocab size]\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        # output = [(tgt length - 1) * batch size, tgt vocab size]\n",
    "        tgt = tgt[1:].view(-1)\n",
    "        # tgt = [(tgt length - 1) * batch size]\n",
    "        loss = criterion(output, tgt)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ],
   "id": "33656d484447460f",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "id": "d808dc880d30b239",
    "ExecuteTime": {
     "end_time": "2024-08-04T14:08:41.769465Z",
     "start_time": "2024-08-04T14:08:41.767244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_fn(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            src = batch[\"src_ids\"].to(device)\n",
    "            tgt = batch[\"tgt_ids\"].to(device)\n",
    "            # src = [src length, batch size]\n",
    "            # tgt = [tgt length, batch size]\n",
    "            output = model(src, tgt, 0)  # turn off teacher forcing\n",
    "            # output = [tgt length, batch size, tgt vocab size]\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            # output = [(tgt length - 1) * batch size, tgt vocab size]\n",
    "            tgt = tgt[1:].view(-1)\n",
    "            # tgt = [(tgt length - 1) * batch size]\n",
    "            loss = criterion(output, tgt)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ],
   "id": "d808dc880d30b239",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "input_dim = sp.get_piece_size()\n",
    "output_dim = sp.get_piece_size()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Hyperparameter tuning loop\n",
    "best_valid_loss = float('inf')\n",
    "best_params = None\n",
    "\n",
    "for params in param_combinations:\n",
    "    batch_size, embedding_dim, hidden_dim, n_layers, dropout, lr, tf_ratio, clip, n_epochs = params\n",
    "\n",
    "    print(f\"Training with parameters: {params}\")\n",
    "\n",
    "    # Update DataLoader with new batch size\n",
    "    train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=get_collate_fn)\n",
    "    dev_data_loader = DataLoader(dev_data, batch_size=batch_size, collate_fn=get_collate_fn)\n",
    "\n",
    "    # Update model with new hyperparameters\n",
    "    encoder = Encoder(input_dim, embedding_dim, hidden_dim, n_layers, dropout)\n",
    "    decoder = Decoder(output_dim, embedding_dim, hidden_dim, n_layers, dropout)\n",
    "    model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "    # Initialize model weights\n",
    "    model.apply(init_weights)\n",
    "\n",
    "    # Update optimizer with new learning rate\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    print(f\"The model has {count_parameters(model):,} trainable parameters\")\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    for epoch in tqdm.tqdm(range(n_epochs)):\n",
    "        train_loss = train_fn(model, train_data_loader, optimizer, criterion, clip, tf_ratio, device)\n",
    "        valid_loss = evaluate_fn(model, dev_data_loader, criterion, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_params = params\n",
    "            torch.save(model.state_dict(), \"best_model.pt\")\n",
    "\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {np.exp(train_loss):.3f}')\n",
    "        print(f'\\tValid Loss: {valid_loss:.3f} | Valid PPL: {np.exp(valid_loss):.3f}')\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")"
   ],
   "metadata": {
    "id": "3xKQ4Yi_mLyV",
    "ExecuteTime": {
     "end_time": "2024-08-04T14:11:31.622895Z",
     "start_time": "2024-08-04T14:11:31.490650Z"
    }
   },
   "id": "3xKQ4Yi_mLyV",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: (128, 256, 256, 2, 0.3, 0.001, 0.25, 0.5, 10)\n",
      "The model has 8,257,344 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'function' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 34\u001B[0m\n\u001B[1;32m     31\u001B[0m valid_losses \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m tqdm\u001B[38;5;241m.\u001B[39mtqdm(\u001B[38;5;28mrange\u001B[39m(n_epochs)):\n\u001B[0;32m---> 34\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m train_fn(model, train_data_loader, optimizer, criterion, clip, tf_ratio, device)\n\u001B[1;32m     35\u001B[0m     valid_loss \u001B[38;5;241m=\u001B[39m evaluate_fn(model, dev_data_loader, criterion, device)\n\u001B[1;32m     37\u001B[0m     train_losses\u001B[38;5;241m.\u001B[39mappend(train_loss)\n",
      "Cell \u001B[0;32mIn[15], line 7\u001B[0m, in \u001B[0;36mtrain_fn\u001B[0;34m(model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device)\u001B[0m\n\u001B[1;32m      5\u001B[0m epoch_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, batch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(data_loader):\n\u001B[0;32m----> 7\u001B[0m     src \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msrc_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m      8\u001B[0m     tgt \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtgt_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;66;03m# src = [src length, batch size]\u001B[39;00m\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;66;03m# tgt = [tgt length, batch size]\u001B[39;00m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'function' object is not subscriptable"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "id": "efdcd1a03e480ad8"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_data_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "model.load_state_dict(torch.load(\"gec-model_2.pt\"))\n",
    "\n",
    "test_loss = evaluate_fn(model, test_data_loader, criterion, device)\n",
    "\n",
    "print(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")"
   ],
   "id": "efdcd1a03e480ad8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "gpuType": "L4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
